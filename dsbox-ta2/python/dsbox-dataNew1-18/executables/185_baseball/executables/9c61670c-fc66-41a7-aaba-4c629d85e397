#!/usr/bin/env python3

import sys
sys.path.append('/dsbox/dsbox-ta2/python')
from dsbox_dev_setup import path_setup
path_setup()

import json
import numpy
import pandas
import os.path
import sklearn.externals
from dsbox.executer.executionhelper import ExecutionHelper
from dsbox.planner.common.data_manager import Dataset, DataManager
from dsbox.planner.common.problem_manager import Problem
from dsbox.schema.problem_schema import TaskType, Metric

# Pipeline : [[Label Encoder, Imputer, sklearn.discriminant_analysis.LinearDiscriminantAnalysis]]


curdir = os.path.dirname(os.path.abspath(__file__))
numpy.set_printoptions(threshold=numpy.nan)

# Defaults unless overridden by config json
dataset_schema = '/home/ta2/dsbox-dataNew1-18/185_baseball/TRAIN/dataset_TRAIN/datasetDoc.json'
problem_schema = '/home/ta2/dsbox-dataNew1-18/185_baseball/TRAIN/problem_TRAIN/problemDoc.json'
problem_root = '/home/ta2/dsbox-dataNew1-18/185_baseball/TRAIN/problem_TRAIN'
test_data_root = '/home/ta2/dsbox-dataNew1-18/185_baseball/TRAIN/dataset_TRAIN'
results_root = '/home/ta2/dsbox-dataNew1-18/executables/185_baseball/results'
executables_root = curdir
temp_storage_root = '/home/ta2/dsbox-dataNew1-18/executables/185_baseball/temp'
numcpus = 10
timeout = 5*60
ram = '16Gi'

config = {}
if len(sys.argv) > 1:
    with open(sys.argv[1]) as conf_data:
        config = json.load(conf_data)
        conf_data.close()
if config.get('dataset_schema', None) is not None:
    dataset_schema = config['dataset_schema']
if config.get('problem_schema', None) is not None:
    problem_schema = config['problem_schema']
if config.get('problem_root', None) is not None:
    problem_root = config['problem_root']
if config.get('test_data_root', None) is not None:
    test_data_root = config['test_data_root']
if config.get('results_root', None) is not None:
    results_root = config['results_root']
if config.get('executables_root', None) is not None:
    executables_root = config['executables_root']
if config.get('temp_storage_root', None) is not None:
    temp_storage_root = config['temp_storage_root']
predictions_file = os.path.join(results_root, 'predictions.csv')
scores_file = os.path.join(results_root, 'scores.csv')

problem = Problem()
problem.load_problem(problem_root, problem_schema)

dataset = Dataset()
dataset.load_dataset(test_data_root, dataset_schema)

data_manager = DataManager()
data_manager.initialize_data(problem, [dataset], view='TEST')

hp = ExecutionHelper(problem, data_manager)
results = []

testdata_0 = data_manager.input_data

print('\nExecuting Label Encoder...')
primfile = temp_storage_root + '/models/9c61670c-fc66-41a7-aaba-4c629d85e397.primitive_1.pkl'
primitive_1 = sklearn.externals.joblib.load(primfile)
testdata_1 = hp.test_execute_primitive(primitive_1, testdata_0)

print('\nExecuting Imputer...')
primfile = temp_storage_root + '/models/9c61670c-fc66-41a7-aaba-4c629d85e397.primitive_2.pkl'
primitive_2 = sklearn.externals.joblib.load(primfile)
testdata_2 = hp.test_execute_primitive(primitive_2, testdata_1)

print('\nExecuting sklearn.discriminant_analysis.LinearDiscriminantAnalysis...')
primfile = temp_storage_root + '/models/9c61670c-fc66-41a7-aaba-4c629d85e397.primitive_3.pkl'
primitive_3 = sklearn.externals.joblib.load(primfile)
result = pandas.DataFrame(primitive_3.executables.produce(inputs=testdata_2).value, index=testdata_2.index, columns=['Hall_of_Fame'])
results.append(result)

print('\nStoring results in %s' % predictions_file)
if not os.path.exists(results_root):
    os.makedirs(results_root)

results_np = numpy.array([df.values for df in results])
weights_np = numpy.array([1]).astype(numpy.int32)
weighted_total = numpy.array([df*const for df, const in zip(results_np, weights_np)])
average_pred = numpy.sum(weighted_total, axis = 0)/numpy.sum(weights_np)
average_pred = numpy.rint(average_pred)
result = pandas.DataFrame(average_pred, index=testdata_0.index, columns=['Hall_of_Fame'])
result.to_csv(predictions_file, index_label='d3mIndex')
